{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "74d126c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from llama_parse import LlamaParse\n",
    "from llama_index.core import SimpleDirectoryReader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7674ade6",
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv()\n",
    "# Load environment variables\n",
    "LLAMA_API_KEY = os.getenv(\"LLAMA_CLOUD_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8be1e9fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "parsing_instruction = \"\"\"\n",
    "You are a document parser. Extract the content into clean, structured markdown format.\n",
    "- Preserve headings, subheadings, paragraphs clearly.\n",
    "- Convert tables into proper markdown table syntax.\n",
    "- Represent images with markdown image syntax ![Description](image_placeholder).\n",
    "- If image data is missing, describe the image briefly in place.\n",
    "- Keep lists, bullet points, and code blocks formatted.\n",
    "- Avoid extra line breaks or broken markdown syntax.\n",
    "\"\"\"\n",
    "\n",
    "# %%\n",
    "# Step 5: Define a function to load and parse PDFs using LlamaParse\n",
    "\n",
    "def load_pdf_as_markdown(pdf_folder: str):\n",
    "    \"\"\"\n",
    "    Load PDF files from a folder, parse with LlamaParse in markdown mode,\n",
    "    using a detailed parsing instruction for better formatting.\n",
    "\n",
    "    Args:\n",
    "        pdf_folder (str): Path to folder with PDFs.\n",
    "\n",
    "    Returns:\n",
    "        List of Document objects with markdown text.\n",
    "    \"\"\"\n",
    "    parser = LlamaParse(\n",
    "        api_key=LLAMA_API_KEY,\n",
    "        result_type=\"markdown\",      # Get markdown output\n",
    "        verbose=True,                # Show parsing logs\n",
    "        parsing_instruction=parsing_instruction,\n",
    "    )\n",
    "\n",
    "    loader = SimpleDirectoryReader(\n",
    "        input_dir=pdf_folder,\n",
    "        file_extractor={\".pdf\": parser}\n",
    "    )\n",
    "\n",
    "    docs = loader.load_data()\n",
    "    return docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a4623d0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def save_docs_as_markdown(docs, save_folder=\"markdown\"):\n",
    "    \"\"\"\n",
    "    Save parsed documents as markdown files in the given folder.\n",
    "\n",
    "    Args:\n",
    "        docs (list): List of Document objects with `.text` attribute.\n",
    "        save_folder (str): Folder name to save markdown files.\n",
    "    \"\"\"\n",
    "    os.makedirs(save_folder, exist_ok=True)\n",
    "\n",
    "    for i, doc in enumerate(docs):\n",
    "        filename = f\"doc_{i+1}.md\"\n",
    "        file_path = os.path.join(save_folder, filename)\n",
    "        with open(file_path, \"w\", encoding=\"utf-8\") as f:\n",
    "            f.write(doc.text)\n",
    "    \n",
    "    print(f\"‚úÖ Saved {len(docs)} markdown files to '{save_folder}' folder.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2e22b4ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: parsing_instruction is deprecated. Use system_prompt, system_prompt_append or user_prompt instead.\n",
      "Started parsing the file under job_id 9e6033f0-f03e-4b7a-a2ca-1d02fb1c1e2e\n",
      "‚úÖ Successfully loaded and parsed 12 document(s).\n",
      "\n",
      "--- Document 1 Preview (Markdown) ---\n",
      "\n",
      "# AN887\n",
      "## APPLICATION NOTE\n",
      "\n",
      "### MICROCONTROLLERS MADE EASY\n",
      "#### by Microcontroller Division Applications\n",
      "\n",
      "### WHAT IS A MICROCONTROLLER?\n",
      "A few years ago, system control functions were implemented using logic components and were usually large, heavy boxes. Later on, microprocessors were used and the entire controller could fit onto a small circuit board. As the process of miniaturization continued, all of the components needed for a controller were built right onto one chip. By only including the features specific to the task, cost is relatively low.\n",
      "\n",
      "A typical microcontroller has bit manipulation instructions, easy and direct access to I/O, and quick and efficient interrupt processing. Therefore, a microcontroller is a highly integrated device which includes, on one chip, all or most of the parts needed to perform an application control function.\n",
      "\n",
      "Microcontrollers come in many varieties. Depending on the power and features that are needed, customers might choose a 4, 8, 16, or 32 bit \n",
      "‚úÖ Saved 12 markdown files to 'markdown' folder.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "pdf_folder_path = \"../data\"  # Your folder containing PDF files\n",
    "docs = load_pdf_as_markdown(pdf_folder_path)\n",
    "\n",
    "print(f\"‚úÖ Successfully loaded and parsed {len(docs)} document(s).\")\n",
    "\n",
    "\n",
    "print(\"\\n--- Document 1 Preview (Markdown) ---\\n\")\n",
    "print(docs[0].text[:1000])\n",
    "\n",
    "# Save all parsed docs as markdown files in \"markdown\" folder\n",
    "\n",
    "save_docs_as_markdown(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "175cbdf8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c9bd794d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.schema import Document\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "456c3157",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 12 markdown documents\n"
     ]
    }
   ],
   "source": [
    "def load_markdown_docs(folder=\"markdown\"):\n",
    "    docs = []\n",
    "    for filename in sorted(os.listdir(folder)):\n",
    "        if filename.endswith(\".md\"):\n",
    "            path = os.path.join(folder, filename)\n",
    "            with open(path, \"r\", encoding=\"utf-8\") as f:\n",
    "                text = f.read()\n",
    "            docs.append(Document(page_content=text, metadata={\"source\": filename}))\n",
    "    return docs\n",
    "\n",
    "markdown_docs = load_markdown_docs()\n",
    "print(f\"Loaded {len(markdown_docs)} markdown documents\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5a806d85",
   "metadata": {},
   "outputs": [],
   "source": [
    "child_splitter = RecursiveCharacterTextSplitter(chunk_size=500, chunk_overlap=50)\n",
    "parent_splitter = RecursiveCharacterTextSplitter(chunk_size=1500, chunk_overlap=200)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f50f5999",
   "metadata": {},
   "outputs": [],
   "source": [
    "chunked_docs = []\n",
    "for doc in markdown_docs:\n",
    "    splits = child_splitter.split_text(doc.page_content)\n",
    "    for i, chunk in enumerate(splits):\n",
    "        chunked_docs.append(\n",
    "            Document(\n",
    "                page_content=chunk,\n",
    "                metadata={\"source\": doc.metadata[\"source\"], \"chunk\": i}\n",
    "            )\n",
    "        )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fd9fb199",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_huggingface import HuggingFaceEmbeddings\n",
    "from langchain.vectorstores import Chroma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bb34446c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\ML(ExtraClass Project)\\RAG_PROJECT\\PDF-AI-Assistant-Chat-Summarize-Quiz-from-PDF\\.pdfassistantenv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "embedding_model = HuggingFaceEmbeddings(\n",
    "    model_name=\"sentence-transformers/all-MiniLM-L6-v2\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c7dd3ade",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\arunp\\AppData\\Local\\Temp\\ipykernel_28896\\1124453161.py:3: LangChainDeprecationWarning: The class `Chroma` was deprecated in LangChain 0.2.9 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-chroma package and should be used instead. To use it run `pip install -U :class:`~langchain-chroma` and import as `from :class:`~langchain_chroma import Chroma``.\n",
      "  vectorstore = Chroma(\n"
     ]
    }
   ],
   "source": [
    "persist_directory = \"../chroma_md\"  # Folder to save vector DB\n",
    "\n",
    "vectorstore = Chroma(\n",
    "    collection_name=\"markdown_chunks\",\n",
    "    embedding_function=embedding_model,\n",
    "    persist_directory=persist_directory\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2b630db2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['8790f183-b84f-4719-a79e-b6d493330e3a',\n",
       " 'ac3bbcb2-81a7-4f86-82c1-54c1050c6c94',\n",
       " '0a384dab-a5c1-4679-b42a-5f34d74b76a8',\n",
       " 'c89b3e70-487a-425a-b910-596d486cf64e',\n",
       " '6a91b78a-31cb-4bc2-bbab-329f01d582e5',\n",
       " 'ff41f57f-156d-4035-8117-592532356aac',\n",
       " '2b86c6b1-0e4c-4101-b6df-113bd889fa9b',\n",
       " 'c5823b8b-2201-4368-a7d0-8003d587a441',\n",
       " '309e8dfc-efaf-455a-b762-807a580d6068',\n",
       " '15c31661-6e34-4850-a64d-7253f81dafa0',\n",
       " '613d8110-75f3-4717-8a9c-0ea1032b7673',\n",
       " '534c1fec-996f-49d8-ac26-7bd4ccfb737e',\n",
       " '54825d07-cda1-4ed4-bb7c-88e3e43791d8',\n",
       " '3dfdee2c-e20d-4365-9370-5b059629add9',\n",
       " '5c12a50b-3a18-4845-b07a-5108d27a9b9c',\n",
       " 'fc1536e2-cda9-46bc-96a5-4019cd5e124b',\n",
       " '40ac397b-74fc-44c7-80c9-94c28680dc96',\n",
       " 'd72b7faa-9d40-4f13-9024-8fa7d4d85717',\n",
       " 'bbf31a28-4425-4d74-9c8c-41095df12ff2',\n",
       " 'f3225c22-9f73-4cfa-901b-80298fba9538',\n",
       " 'b861ae97-33ca-49c9-a1e4-bffffabe4c4d',\n",
       " '11092d5e-a3ed-4b8c-b954-46c2435f6a9d',\n",
       " '89afcb3b-57df-4957-9791-b97d02eb040d',\n",
       " '2241ce00-fced-4581-8b2e-751abd02d8b2',\n",
       " '025a3552-06d0-4a78-9c96-db415be199b5',\n",
       " '0aeae7c4-0303-4b43-9abd-bc741f618071',\n",
       " '204b205a-c6b2-4597-b937-950911fdcfa5',\n",
       " '7d0a0012-31ee-4beb-aa2e-220e9f8f0634',\n",
       " '660cb511-6c25-4e29-a284-4fe3c83b5b59',\n",
       " '5440caeb-1401-4e71-a18c-c5d4ffd1f22e',\n",
       " '4520b672-05e1-4c37-8463-ab25bd9e6c12',\n",
       " 'ed6d473e-eccc-4e0a-8823-1ca5bf6efafc',\n",
       " '6d81eb75-447e-4cb0-8ddf-a10bc352eea6',\n",
       " '3538c508-b918-4bb7-8961-7995abfabfc6',\n",
       " 'd4479c4b-1ffb-485a-9f74-4644627f4f07',\n",
       " '6d6c4fdf-3dd3-43a6-839c-3ec8411daeaf',\n",
       " '4013fbdb-4d73-44f3-aa9e-71a4beebd013',\n",
       " '30a90708-adf2-42b7-9c05-19103663af73',\n",
       " '313c9cd2-fb92-44bc-bec3-fc18dfe31f62',\n",
       " '05511a0c-9dee-413b-9467-6da49fc38a50',\n",
       " '3bf24ec4-3d1f-4403-a96a-4ec558083db3',\n",
       " 'd61364da-922f-4d96-9be8-b931d11bf31c',\n",
       " '305911f1-5d54-4dd2-8dca-b82641af1ac2',\n",
       " '0b7e92d4-f884-4110-a4a3-7ea937e45e16',\n",
       " 'bb8655ba-ddec-440c-b71b-594e56062bdc',\n",
       " 'ef407b26-8993-40bd-b2d7-c5cc19d49b78',\n",
       " '05192172-57e2-4d46-9aa7-8e6cb34050fc',\n",
       " 'e0120ee7-5255-4985-b487-31356d99aff6',\n",
       " '74b5ff85-820c-4a50-9fd3-c9dbe5e445a1',\n",
       " '36e0f6b8-cf4a-4a5d-a12a-1b032120faec',\n",
       " '55d4f3fa-2ead-4656-a47b-57b4cdd3dbf2',\n",
       " 'fb0558df-5c4b-45b5-b6b6-3e936684e902',\n",
       " 'dc612f7c-e608-4ec7-9a29-0cd3b5885c16',\n",
       " '0840a19c-2a64-4094-8016-5172ca4c09b3',\n",
       " '5eeee2ba-e196-48b5-8754-4d17dd98e215',\n",
       " 'ecd088ba-5348-4c6d-890a-d51066d1c2be',\n",
       " '630ce94f-2ad5-49af-a758-190d162668eb',\n",
       " '978f9f46-c10f-45c2-ab1a-336f2d4a16ca',\n",
       " '5870d04b-8193-4a82-8d6f-5471fb630d69',\n",
       " '1f4a6d1c-77d1-432f-8771-fd08df50e213',\n",
       " 'f4c262ea-4527-4633-b956-ffe095cdcdc7',\n",
       " 'dd176d8a-a81a-4bfe-833c-951477f3024b',\n",
       " 'a520a65f-b002-4ebb-b002-6bd5855e0469',\n",
       " 'd195ec75-f611-4ab9-9286-b748d3fdbc01',\n",
       " '5609c5df-ee3d-4ec2-ba56-605e176552ad',\n",
       " 'ff2d3f0a-f689-49f1-ba12-e418f1764ebe',\n",
       " '6ed9dfee-b991-4f6a-857b-416fa559acc7',\n",
       " '75c3c955-8b73-43fb-824c-807fd54c3e76',\n",
       " '0c7044d2-4129-4c5c-bf21-d59333db4b3b',\n",
       " '4a57d1a0-328a-4cc8-8142-ec66697bfeef',\n",
       " '93b0ff9e-5330-4494-8c68-8099def38a3b']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Add chunks to vector store\n",
    "vectorstore.add_documents(chunked_docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "15d54176",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stored 71 chunks in Chroma vector store.\n"
     ]
    }
   ],
   "source": [
    "print(f\"Stored {len(chunked_docs)} chunks in Chroma vector store.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38e9cd38",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b42e1ff3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.retrievers import ParentDocumentRetriever\n",
    "from langchain.storage import InMemoryStore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "588f7a65",
   "metadata": {},
   "outputs": [],
   "source": [
    "docstore = InMemoryStore()  # For storing full parent docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a92c6aa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever = ParentDocumentRetriever(\n",
    "    vectorstore=vectorstore,\n",
    "    docstore=docstore,\n",
    "    child_splitter=child_splitter,\n",
    "    parent_splitter=parent_splitter\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "40bbc8b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ ParentDocumentRetriever is ready.\n"
     ]
    }
   ],
   "source": [
    "retriever.add_documents(markdown_docs)  # Add full markdown docs as parents\n",
    "print(\"‚úÖ ParentDocumentRetriever is ready.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4723e238",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "20938e98",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import PromptTemplate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "328ac3f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 1. Chat Prompt\n",
    "chat_prompt = PromptTemplate.from_template(\"\"\"\n",
    "You are a helpful assistant. Use the context below to answer the question.\n",
    "If the answer is not found, say so.\n",
    "\n",
    "Context:\n",
    "{context}\n",
    "\n",
    "Question:\n",
    "{question}\n",
    "\"\"\")\n",
    "\n",
    "# 2. Summarization Prompt\n",
    "summarize_prompt = PromptTemplate.from_template(\"\"\"\n",
    "You are an expert summarizer. Your task is to read the provided document context and generate a comprehensive, well-structured summary that captures all key points, main ideas, and important details.\n",
    "\n",
    "Instructions:\n",
    "- Organize the summary with clear headings and bullet points where appropriate.\n",
    "- Highlight major sections, concepts, and any lists or processes described in the context.\n",
    "- Use concise language, but do not omit critical information.\n",
    "- If the context includes tables, describe their content in summary form.\n",
    "- If there are images or diagrams referenced, briefly mention their purpose or content.\n",
    "- The summary should be easy to read and suitable for someone who needs a quick but thorough understanding of the document.\n",
    "\n",
    "Context:\n",
    "{context}\n",
    "\n",
    "Summary:\n",
    "\"\"\")\n",
    "\n",
    "# 3. Quiz Prompt\n",
    "quiz_prompt = PromptTemplate.from_template(\"\"\"\n",
    "You are a quiz generator. Create {num_questions} MCQs from the context below.\n",
    "\n",
    "Context:\n",
    "{context}\n",
    "\"\"\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "9e54f28f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv()  # Load environment variables from .env file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b3bd193c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_groq import ChatGroq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "5672cdb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = ChatGroq(model_name=\"llama-3.1-8b-instant\", temperature=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8865eb8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "607a9c2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.output_parsers import StrOutputParser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "876c3193",
   "metadata": {},
   "outputs": [],
   "source": [
    "parser = StrOutputParser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c594b718",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0aa16d96",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "7e35e315",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Building a chain for our RAG system"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "01273e1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.schema.runnable import RunnableSequence, RunnableLambda, RunnablePassthrough , RunnableBranch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "f242760b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ‚úÖ Retrieve context using question\n",
    "context_retriever = RunnableLambda(\n",
    "    lambda x: {\"context\": retriever.get_relevant_documents(x.get(\"question\", \"\")), **x}\n",
    ")\n",
    "\n",
    "# ‚úÖ Formatters\n",
    "chat_formatter = RunnableLambda(lambda x: {\n",
    "    \"context\": \"\\n\\n\".join([doc.page_content for doc in x.get(\"context\", [])]),\n",
    "    \"question\": x.get(\"question\", \"\")\n",
    "})\n",
    "\n",
    "summarize_formatter = RunnableLambda(lambda x: {\n",
    "    \"context\": \"\\n\\n\".join([doc.page_content for doc in x.get(\"context\", [])])\n",
    "})\n",
    "\n",
    "quiz_formatter = RunnableLambda(lambda x: {\n",
    "    \"context\": \"\\n\\n\".join([doc.page_content for doc in x.get(\"context\", [])]),\n",
    "    \"num_questions\": x.get(\"num_questions\", 5)\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "fe736972",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "chat_chain = RunnableSequence(\n",
    "    context_retriever,\n",
    "    chat_formatter,\n",
    "    chat_prompt,\n",
    "    llm,\n",
    "    parser\n",
    ")\n",
    "\n",
    "summarize_chain = RunnableSequence(\n",
    "    context_retriever,\n",
    "    summarize_formatter,\n",
    "    summarize_prompt,\n",
    "    llm,\n",
    "    parser\n",
    ")\n",
    "\n",
    "quiz_chain = RunnableSequence(\n",
    "    context_retriever,\n",
    "    quiz_formatter,\n",
    "    quiz_prompt,\n",
    "    llm,\n",
    "    parser\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fbc7294",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ‚úÖ SAFE conditions\n",
    "def is_chat_mode(x):\n",
    "    return x.get(\"mode\", \"\").lower() == \"chat\"\n",
    "\n",
    "def is_summarize_mode(x):\n",
    "    return x.get(\"mode\", \"\").lower() == \"summarize\"\n",
    "\n",
    "def is_quiz_mode(x):\n",
    "    return x.get(\"mode\", \"\").lower() == \"quiz\"\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "rag_mode_chain = RunnableBranch(\n",
    "    (is_chat_mode, chat_chain),\n",
    "    (is_summarize_mode, summarize_chain),\n",
    "    (is_quiz_mode, quiz_chain),\n",
    "    RunnableLambda(lambda x: \" Invalid mode selected. Choose 'chat', 'summarize', or 'quiz'.\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "fe2a5c17",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\arunp\\AppData\\Local\\Temp\\ipykernel_28896\\2988116568.py:3: LangChainDeprecationWarning: The method `BaseRetriever.get_relevant_documents` was deprecated in langchain-core 0.1.46 and will be removed in 1.0. Use :meth:`~invoke` instead.\n",
      "  lambda x: {\"context\": retriever.get_relevant_documents(x.get(\"question\", \"\")), **x}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üó£Ô∏è Chat Response:\n",
      " A microcontroller is a highly integrated device which includes, on one chip, all or most of the parts needed to perform an application control function. It typically has bit manipulation instructions, easy and direct access to I/O, and quick and efficient interrupt processing.\n",
      "\n",
      "üßæ Summary:\n",
      " **Microcontrollers Made Easy: Communication and Automotive Market**\n",
      "\n",
      "**2.4 Communication: CAN & J1850**\n",
      "\n",
      "* **CAN (Controller Area Network)**: A multiplexed wiring scheme developed by BOSH and Intel for automotive applications.\n",
      "* **J1850**: The SAE multiplexed automotive wiring standard used in North America.\n",
      "* **CAN Specification**: Widely used in industrial control in North America and Europe.\n",
      "* **Lower Cost Microcontrollers**: Supporting CAN has the potential to increase its adoption.\n",
      "\n",
      "**CAN Principle**\n",
      "\n",
      "* The table illustrates the different systems and their corresponding speeds:\n",
      "\t+ **Fast Speed**: ABS/ASR, >125Kb/s\n",
      "\t+ **Slow Speed**: >125Kb/s\n",
      "\t+ **Inter System**: Motor, Dashboard, Fuse Box, Air Conditioner, etc.\n",
      "\n",
      "**The Automotive Market**\n",
      "\n",
      "* The automotive market is the primary driving force in the microcontroller market, especially at the high end.\n",
      "* **Microcontroller Families**: Developed specifically for automotive applications and later modified for other embedded applications.\n",
      "\n",
      "**MCU Applications in Automotive**\n",
      "\n",
      "* The table shows various automotive applications and their corresponding microcontroller components:\n",
      "\t+ **Fuel Injection**: VR02101F\n",
      "\t+ **Trip Computer**: \n",
      "\t+ **Window Lift**: \n",
      "\t+ **Keyless Entry**: \n",
      "\t+ **Car Radio**: \n",
      "\t+ **Airbag**: \n",
      "\t+ **Seat Belt Fastener**: \n",
      "\t+ **Dashboard Display**: VR02101F\n",
      "\n",
      "**Automotive Market Demands**\n",
      "\n",
      "* High device performance and component reliability.\n",
      "* Electronics must operate under extreme temperatures and withstand vibration, shock, and EMI.\n",
      "* Reliability standards are high, but the electronics also compete in the consumer market, resulting in a low price tag.\n",
      "\n",
      "üß† Quiz:\n",
      " Here are 3 MCQs based on the given context:\n",
      "\n",
      "**Question 1**\n",
      "What is the primary difference between polling and interrupts in microcontrollers?\n",
      "\n",
      "A) Polling is faster than interrupts\n",
      "B) Polling is used for time-critical tasks, while interrupts are used for non-time-critical tasks\n",
      "C) Polling involves peripherals telling the controller when they have data ready, while interrupts involve the controller continually asking peripherals for data\n",
      "D) Polling is used for single tasks, while interrupts are used for multiple tasks\n",
      "\n",
      "**Answer: C) Polling involves peripherals telling the controller when they have data ready, while interrupts involve the controller continually asking peripherals for data**\n",
      "\n",
      "**Question 2**\n",
      "What is the main purpose of microcontrollers?\n",
      "\n",
      "A) To implement a set of control functions in the most cost-effective way\n",
      "B) To achieve maximum processing performance\n",
      "C) To control complex systems with multiple processors\n",
      "D) To implement a set of control functions with maximum processing performance\n",
      "\n",
      "**Answer: A) To implement a set of control functions in the most cost-effective way**\n",
      "\n",
      "**Question 3**\n",
      "What is the typical application of microcontrollers in cars?\n",
      "\n",
      "A) Entertainment systems only\n",
      "B) Engine control, diagnostics, climate control, and other control functions\n",
      "C) Only body control systems\n",
      "D) Only dashboard displays\n",
      "\n",
      "**Answer: B) Engine control, diagnostics, climate control, and other control functions**\n"
     ]
    }
   ],
   "source": [
    "# CHAT\n",
    "response_chat = rag_mode_chain.invoke({\n",
    "    \"mode\": \"chat\",\n",
    "    \"question\": \"What is a microcontroller?\"\n",
    "})\n",
    "print(\"üó£Ô∏è Chat Response:\\n\", response_chat)\n",
    "\n",
    "# SUMMARIZE\n",
    "response_summary = rag_mode_chain.invoke({\n",
    "    \"mode\": \"summarize\",\n",
    "    \"question\": \"Summarize the document\"  # used only to retrieve relevant context\n",
    "})\n",
    "print(\"\\nüßæ Summary:\\n\", response_summary)\n",
    "\n",
    "# QUIZ (dynamic question count)\n",
    "response_quiz = rag_mode_chain.invoke({\n",
    "    \"mode\": \"quiz\",\n",
    "    \"question\": \"Generate quiz\",\n",
    "    \"num_questions\": 3  # üî¢ user-controlled!\n",
    "})\n",
    "print(\"\\nüß† Quiz:\\n\", response_quiz)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".pdfassistantenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
