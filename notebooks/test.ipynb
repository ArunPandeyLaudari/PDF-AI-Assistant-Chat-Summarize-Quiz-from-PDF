{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "928e7296",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from llama_parse import LlamaParse\n",
    "from langchain_core.documents import Document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "35996fd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv()\n",
    "LLAMA_API_KEY = os.getenv(\"LLAMA_CLOUD_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1eca10ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: parsing_instruction is deprecated. Use system_prompt, system_prompt_append or user_prompt instead.\n",
      "Started parsing the file under job_id d65654c6-46e2-4ba6-b174-96a004d9565b\n",
      " Saved 12 markdown files to 'markdown'\n"
     ]
    }
   ],
   "source": [
    "parsing_instruction = \"\"\"\n",
    "You are a document parser. Extract the content into clean, structured markdown format.\n",
    "- Preserve headings, subheadings, paragraphs clearly.\n",
    "- Convert tables into proper markdown table syntax.\n",
    "- Represent images with markdown image syntax ![Description](image_placeholder).\n",
    "- If image data is missing, describe the image briefly in place.\n",
    "- Keep lists, bullet points, and code blocks formatted.\n",
    "- Avoid extra line breaks or broken markdown syntax.\n",
    "\"\"\"\n",
    "\n",
    "def parse_single_pdf(pdf_path: str) -> list:\n",
    "    parser = LlamaParse(\n",
    "        api_key=LLAMA_API_KEY,\n",
    "        result_type=\"markdown\",\n",
    "        verbose=True,\n",
    "        parsing_instruction=parsing_instruction,\n",
    "    )\n",
    "    return parser.load_data(pdf_path)\n",
    "\n",
    "def save_markdown(docs, folder=\"markdown\"):\n",
    "    os.makedirs(folder, exist_ok=True)\n",
    "    for i, doc in enumerate(docs):\n",
    "        with open(os.path.join(folder, f\"doc_{i+1}.md\"), \"w\", encoding=\"utf-8\") as f:\n",
    "            f.write(doc.text)\n",
    "    print(f\" Saved {len(docs)} markdown files to '{folder}'\")\n",
    "\n",
    "pdf_path = \"../data/testing5.pdf\"  #  Provide full path to single PDF\n",
    "docs = parse_single_pdf(pdf_path)\n",
    "save_markdown(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "644c8777",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain_core.documents import Document as LCDocument"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a4419ad4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Loaded 12 markdown documents\n"
     ]
    }
   ],
   "source": [
    "# Load markdown as LangChain documents\n",
    "def load_markdown_docs(folder=\"markdown\"):\n",
    "    loaded_docs = []\n",
    "    for filename in os.listdir(folder):\n",
    "        if filename.endswith(\".md\"):\n",
    "            with open(os.path.join(folder, filename), \"r\", encoding=\"utf-8\") as f:\n",
    "                text = f.read()\n",
    "            loaded_docs.append(LCDocument(page_content=text, metadata={\"source\": filename}))\n",
    "    return loaded_docs\n",
    "\n",
    "markdown_docs = load_markdown_docs()\n",
    "print(f\" Loaded {len(markdown_docs)} markdown documents\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "280bf1b4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2601f91a",
   "metadata": {},
   "outputs": [],
   "source": [
    "child_splitter = RecursiveCharacterTextSplitter(chunk_size=500, chunk_overlap=50)\n",
    "parent_splitter = RecursiveCharacterTextSplitter(chunk_size=1500, chunk_overlap=200)\n",
    "\n",
    "chunked_docs = []\n",
    "for doc in markdown_docs:\n",
    "    for i, chunk in enumerate(child_splitter.split_text(doc.page_content)):\n",
    "        chunked_docs.append(LCDocument(\n",
    "            page_content=chunk,\n",
    "            metadata={\"source\": doc.metadata[\"source\"], \"chunk\": i}\n",
    "        ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "06b4cc62",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stored 71 chunks in Chroma vector store.\n"
     ]
    }
   ],
   "source": [
    "from langchain_huggingface import HuggingFaceEmbeddings\n",
    "from langchain_chroma import Chroma\n",
    "\n",
    "embedding_model = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-MiniLM-L6-v2\")\n",
    "persist_directory = \"chroma_db\"\n",
    "\n",
    "vectorstore = Chroma(\n",
    "    collection_name=\"md_chunks\",\n",
    "    embedding_function=embedding_model,\n",
    "    persist_directory=persist_directory\n",
    ")\n",
    "\n",
    "if chunked_docs:\n",
    "    vectorstore.add_documents(chunked_docs)\n",
    "    print(f\"Stored {len(chunked_docs)} chunks in Chroma vector store.\")\n",
    "else:\n",
    "    print(\"No chunks to store in Chroma vector store.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39f11369",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88ce60fc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "bc424741",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " ParentDocumentRetriever ready.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from langchain.retrievers import ParentDocumentRetriever\n",
    "from langchain.storage import InMemoryStore\n",
    "\n",
    "docstore = InMemoryStore()\n",
    "retriever = ParentDocumentRetriever(\n",
    "    vectorstore=vectorstore,\n",
    "    docstore=docstore,\n",
    "    child_splitter=child_splitter,\n",
    "    parent_splitter=parent_splitter\n",
    ")\n",
    "retriever.add_documents(markdown_docs)\n",
    "print(\" ParentDocumentRetriever ready.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b67bcf2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "14f5ca85",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import PromptTemplate\n",
    "\n",
    "chat_prompt = PromptTemplate.from_template(\"\"\"\n",
    "You are a helpful assistant. Use the context below to answer the question.\n",
    "If the answer is not found, say so.\n",
    "\n",
    "Context:\n",
    "{context}\n",
    "\n",
    "Question:\n",
    "{question}\n",
    "\"\"\")\n",
    "\n",
    "summarize_prompt = PromptTemplate.from_template(\"\"\"\n",
    "You are an expert summarizer. Read the context and summarize key points, headings, and lists.\n",
    "\n",
    "Context:\n",
    "{context}\n",
    "\n",
    "Summary:\n",
    "\"\"\")\n",
    "\n",
    "quiz_prompt = PromptTemplate.from_template(\"\"\"\n",
    "You are a quiz generator. Create {num_questions} MCQs from the context.\n",
    "\n",
    "Context:\n",
    "{context}\n",
    "\"\"\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54ac74fe",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "03bd343f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_groq import ChatGroq\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "llm = ChatGroq(model_name=\"llama-3.1-8b-instant\", temperature=0.2)\n",
    "parser = StrOutputParser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a206a047",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b7a8665e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.schema.runnable import RunnableSequence, RunnableLambda, RunnableBranch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "116ae9c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Formatters\n",
    "context_retriever = RunnableLambda(lambda x: {\"context\": retriever.invoke(x.get(\"question\", \"\")), **x})\n",
    "\n",
    "chat_formatter = RunnableLambda(lambda x: {\n",
    "    \"context\": \"\\n\\n\".join(doc.page_content for doc in x.get(\"context\", [])),\n",
    "    \"question\": x.get(\"question\", \"\")\n",
    "})\n",
    "\n",
    "summarize_formatter = RunnableLambda(lambda x: {\n",
    "    \"context\": \"\\n\\n\".join(doc.page_content for doc in x.get(\"context\", []))\n",
    "})\n",
    "\n",
    "quiz_formatter = RunnableLambda(lambda x: {\n",
    "    \"context\": \"\\n\\n\".join(doc.page_content for doc in x.get(\"context\", [])),\n",
    "    \"num_questions\": x.get(\"num_questions\", 5)\n",
    "})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "3f08c169",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chains\n",
    "chat_chain = RunnableSequence(context_retriever, chat_formatter, chat_prompt, llm, parser)\n",
    "summarize_chain = RunnableSequence(context_retriever, summarize_formatter, summarize_prompt, llm, parser)\n",
    "quiz_chain = RunnableSequence(context_retriever, quiz_formatter, quiz_prompt, llm, parser)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "6ac9fdf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_chat(x): return x.get(\"mode\") == \"chat\"\n",
    "def is_summary(x): return x.get(\"mode\") == \"summarize\"\n",
    "def is_quiz(x): return x.get(\"mode\") == \"quiz\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "a513c6a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "rag_chain = RunnableBranch(\n",
    "    (is_chat, chat_chain),\n",
    "    (is_summary, summarize_chain),\n",
    "    (is_quiz, quiz_chain),\n",
    "    RunnableLambda(lambda _: \" Invalid mode. Choose 'chat', 'summarize', or 'quiz'.\")\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "d75551fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🗣️ Chat: A microcontroller is a highly integrated device which includes, on one chip, all or most of the parts needed to perform an application control function. It typically has bit manipulation instructions, easy and direct access to I/O, and quick and efficient interrupt processing.\n",
      "\n",
      "🧾 Summary: **Summary of Microcontrollers Made Easy**\n",
      "\n",
      "**Key Components of a Microcontroller:**\n",
      "\n",
      "1. **Flash**: Electrically erasable and programmable memory that can store program instructions and data.\n",
      "2. **RAM (Random Access Memory)**: Temporary storage of data during program execution.\n",
      "3. **EEPROM (Electrically Erasable Programmable Read Only Memory)**: Stores data that must be saved through a power down cycle.\n",
      "4. **CPU (Central Processing Unit)**: The brain of the system that processes data and executes instructions.\n",
      "\n",
      "**Microcontroller Block Organization:**\n",
      "\n",
      "* CPU (Central Processing Unit)\n",
      "* Flash Memory\n",
      "* RAM (Random Access Memory)\n",
      "* EEPROM (Electrically Erasable Programmable Read Only Memory)\n",
      "* Other peripherals (e.g. timers, counters, serial communication interfaces)\n",
      "\n",
      "**Communication Protocols:**\n",
      "\n",
      "1. **CAN (Controller Area Network)**: A multiplexed wiring scheme used in automobiles and industrial control systems.\n",
      "2. **J1850**: The SAE (Society of Automotive Engineers) multiplexed automotive wiring standard used in North America.\n",
      "\n",
      "**CAN Bus Applications:**\n",
      "\n",
      "| System | Fast Speed | Slow Speed |\n",
      "| --- | --- | --- |\n",
      "| Motor | ABS / ASR | >125Kb/s |\n",
      "| Dashboard | | |\n",
      "| Fuse Box | | |\n",
      "| Air Conditioner | | |\n",
      "| Comfort | Radio, Display | Navigation System, Phone |\n",
      "| Body | Window, Lock | Seat, Lamps |\n",
      "\n",
      "**Key Points:**\n",
      "\n",
      "* Microcontrollers have various memory types (Flash, RAM, EEPROM) for storing program instructions and data.\n",
      "* The CPU is the brain of the system that processes data and executes instructions.\n",
      "* Communication protocols like CAN and J1850 are used in industrial control systems and automobiles.\n",
      "* CAN bus is a multiplexed wiring scheme that supports fast and slow speed applications.\n",
      "\n",
      "🧠 Quiz:\n",
      " Here are 3 MCQs based on the given context:\n",
      "\n",
      "**Question 1**\n",
      "What is the primary difference between polling and interrupts in microcontrollers?\n",
      "\n",
      "A) Polling is faster than interrupts\n",
      "B) Polling is used for time-critical tasks, while interrupts are used for non-time-critical tasks\n",
      "C) Polling is a software technique where peripherals tell the controller when they have data ready\n",
      "D) Polling is used when the microcontroller has interrupts, while interrupts are used when the microcontroller does not have interrupts\n",
      "\n",
      "**Answer: C) Polling is a software technique where peripherals tell the controller when they have data ready**\n",
      "\n",
      "**Question 2**\n",
      "What is the main purpose of microcontrollers?\n",
      "\n",
      "A) To implement a set of control functions in the most cost-effective way\n",
      "B) To achieve maximum processing performance\n",
      "C) To control complex systems with multiple processors\n",
      "D) To implement a set of control functions with maximum processing performance\n",
      "\n",
      "**Answer: A) To implement a set of control functions in the most cost-effective way**\n",
      "\n",
      "**Question 3**\n",
      "What is the name of the microcontroller mentioned in the context as being used to control a microwave oven?\n",
      "\n",
      "A) ST6\n",
      "B) Pentium\n",
      "C) ST7\n",
      "D) ST8\n",
      "\n",
      "**Answer: A) ST6**\n"
     ]
    }
   ],
   "source": [
    "chat_response = rag_chain.invoke({\n",
    "    \"mode\": \"chat\",\n",
    "    \"question\": \"What is a microcontroller?\"\n",
    "})\n",
    "print(\"🗣️ Chat:\", chat_response)\n",
    "\n",
    "summary_response = rag_chain.invoke({\n",
    "    \"mode\": \"summarize\",\n",
    "    \"question\": \"Summarize this\"  # for retrieval\n",
    "})\n",
    "print(\"\\n🧾 Summary:\", summary_response)\n",
    "\n",
    "quiz_response = rag_chain.invoke({\n",
    "    \"mode\": \"quiz\",\n",
    "    \"question\": \"Generate quiz\",\n",
    "    \"num_questions\": 3\n",
    "})\n",
    "print(\"\\n🧠 Quiz:\\n\", quiz_response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6146863d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".pdfassistantenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
